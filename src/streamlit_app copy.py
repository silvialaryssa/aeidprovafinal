import csv
from xml.parsers.expat import model
from sklearn import pipeline
import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import numpy as np
from sklearn.linear_model import LassoCV
import altair as alt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import het_breuschpagan
from scipy.stats import shapiro
import statsmodels.api as sm
import streamlit as st
import pandas as pd
import plotly.express as px

# ================================
# üìÜ FUN√á√ïES UTILIT√ÅRIAS
# ================================
@st.cache_data
def carregar_dados(uploaded_file=None):
    DEFAULT_FILE = 'src/kc_house_data.csv'
    if uploaded_file is not None:
        return pd.read_csv(uploaded_file)
    else:
        return pd.read_csv(DEFAULT_FILE)

def upload_multiplos_datasets(questoes):
    st.sidebar.markdown("### üìÅ Upload de Arquivos por Quest√£o")
    arquivos = {}
    for questao in questoes:
        arquivos[questao] = st.sidebar.file_uploader(
            f"üîπ Arquivo para {questao}", type=["csv"], key=f"upload_{questao}"
        )
    return arquivos



def avaliar_pressupostos(X, y_true, y_pred):
  #########################
    # Supondo que voc√™ j√° tenha y_pred e residuos como arrays ou Series
    df_residuos = pd.DataFrame({
        "Valores previstos": y_pred,
        "Res√≠duos": y_true - y_pred  # ou residuos, se j√° estiver pronto
    })

    # Gr√°fico de dispers√£o com linha horizontal em y=0
    scatter = alt.Chart(df_residuos).mark_circle(size=60, opacity=0.6).encode(
        x=alt.X("Valores previstos", title="Valores previstos"),
        y=alt.Y("Res√≠duos", title="Res√≠duos"),
        tooltip=["Valores previstos", "Res√≠duos"]
    ).properties(
        width=400,
        height=300,
        title="Res√≠duos vs Valores previstos"
    )

    linha_zero = alt.Chart(pd.DataFrame({"y": [0]})).mark_rule(color='red', strokeDash=[5,5]).encode(
        y='y'
    )

    # Combine scatter + linha zero
    chart = scatter + linha_zero

    st.altair_chart(chart, use_container_width=True)
    
  #######################

def ajustar_modelo_lasso(X,y):
    """
    Ajusta um modelo de regress√£o Lasso com valida√ß√£o cruzada.
    Retorna o modelo treinado e os coeficientes.
    """
    st.markdown("### üîç Ajuste do Modelo com Lasso (com valida√ß√£o cruzada)")

    # Ajusta o modelo com valida√ß√£o cruzada para escolher o melhor alpha
    lasso = LassoCV(cv=5, random_state=42).fit(X, y)
    coef_lasso = pd.Series(lasso.coef_, index=X.columns)

    # Exibe os resultados
    st.write(f"Melhor alpha (Œª): {lasso.alpha_:.6f}")
    st.markdown("### üìå Coeficientes do Lasso")
    st.dataframe(coef_lasso[coef_lasso != 0].sort_values(ascending=False))

    return lasso


# =================
# Fun√ß√£o para Remover Outliers com IQR
# =================
def remover_outliers_iqr(df, colunas=None, threshold=1.5):
    """
    Removes outliers from numeric columns based on the IQR method.
    Parameters:
        df: Original DataFrame
        colunas: list of numeric columns to evaluate (if None, applies to all)
        threshold: IQR multiplier to define limits (default: 1.5)
    Returns:
        DataFrame without outliers
    """
    if colunas is None:
        colunas = df.select_dtypes(include='number').columns.tolist()

    df_sem_outliers = df.copy()
    for col in colunas:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior = Q1 - threshold * IQR
        limite_superior = Q3 + threshold * IQR
        df_sem_outliers = df_sem_outliers[
            (df_sem_outliers[col] >= limite_inferior) & (df_sem_outliers[col] <= limite_superior)
        ]

    return df_sem_outliers




# =============================
# üîß Fun√ß√µes - Quest√£o 1
# =============================
def q1_etapa1():
    st.markdown("---")
    def exibir_dicionario_variaveis():
        st.markdown("### üìò Dicion√°rio de Vari√°veis")
        st.markdown("""
        | Coluna            | Tradu√ß√£o                        | Descri√ß√£o                                                                 |
        |-------------------|----------------------------------|---------------------------------------------------------------------------|
        | `id`              | Identificador                   | ID √∫nico do im√≥vel                                                        |
        | `date`            | Data da venda                   | Data em que o im√≥vel foi vendido                                          |
        | `price`           | Pre√ßo                           | Pre√ßo de venda do im√≥vel (vari√°vel alvo)                                 |
        | `bedrooms`        | Quartos                         | N√∫mero de quartos                                                         |
        | `bathrooms`       | Banheiros                       | N√∫mero de banheiros (valores podem ser fracionados)                      |
        | `sqft_living`     | √Årea √∫til (p√©s¬≤)                | √Årea interna utiliz√°vel do im√≥vel                                        |
        | `sqft_lot`        | √Årea do terreno (p√©s¬≤)         | Tamanho do lote do im√≥vel                                                |
        | `floors`          | Andares                         | N√∫mero de andares                                                         |
        | `waterfront`      | Frente para o mar               | 1 se o im√≥vel tem vista para o mar; 0 caso contr√°rio                      |
        | `view`            | Visibilidade/Vis√£o              | Grau de qualidade da vista (0‚Äì4)                                          |
        | `condition`       | Condi√ß√£o                        | Condi√ß√£o geral do im√≥vel (1‚Äì5)                                            |
        | `grade`           | Qualidade de constru√ß√£o         | Avalia√ß√£o da qualidade da constru√ß√£o (1‚Äì13)                               |
        | `sqft_above`      | √Årea acima do solo (p√©s¬≤)       | √Årea constru√≠da acima do solo                                            |
        | `sqft_basement`   | √Årea do por√£o (p√©s¬≤)            | √Årea do por√£o                                                             |
        | `yr_built`        | Ano de constru√ß√£o               | Ano original de constru√ß√£o                                                |
        | `yr_renovated`    | Ano de reforma                  | Ano da √∫ltima reforma (0 se nunca reformado)                             |
        | `zipcode`         | CEP                             | C√≥digo postal                                                             |
        | `lat`             | Latitude                        | Coordenada de latitude                                                    |
        | `long`            | Longitude                       | Coordenada de longitude                                                   |
        | `sqft_living15`   | √Årea √∫til dos vizinhos (p√©s¬≤)   | M√©dia da √°rea √∫til das 15 casas mais pr√≥ximas                             |
        | `sqft_lot15`      | √Årea dos terrenos vizinhos      | M√©dia do tamanho dos lotes das 15 casas mais pr√≥ximas                     |
            """)
        
    st.subheader("üè† Q1 - 1 - Regress√£o Linear - An√°lise Descritiva dos Dados")
    exibir_dicionario_variaveis()
    uploaded_file = 'src/kc_house_data.csv'

    df = carregar_dados(uploaded_file)
    st.session_state["kc_df"] = df
    st.success("‚úÖ Arquivo carregado com sucesso!")

    st.markdown("### üîç Preview dos Dados")
    #st.dataframe(df.head())
    #st.dataframe(df)

    st.markdown("### üìä Estat√≠sticas Descritivas")
    st.dataframe(df.describe())

    st.markdown("### üßÆ Mediana das Vari√°veis Num√©ricas")
    st.dataframe(df.median(numeric_only=True))

    if "price" in df.columns:
        # excluindo as variaves id e zipcod
        st.markdown("### üîó Correla√ß√£o com o Pre√ßo (`price`)")
        correlacoes = df.drop(columns=["id", "zipcode"], errors='ignore').corr(numeric_only=True)["price"].sort_values(ascending=False)
        st.write(correlacoes)

        st.markdown("### üî• Mapa de Correla√ß√£o")
        plt.figure(figsize=(10, 8))
        # excluindo as variaves id e zipcod
        sns.heatmap(df.drop(columns=["id"], errors='ignore').corr(numeric_only=True), annot=True, fmt=".2f", cmap="coolwarm")
        st.pyplot(plt.gcf())
        plt.clf()
        
        #corr = df.drop(columns=["id", "price"], errors='ignore').corr(numeric_only=True)
        #corr = corr.reset_index().melt('index')
        #corr.columns = ['Var1', 'Var2', 'Correlacao']

        #heatmap = alt.Chart(corr).mark_rect().encode(
        #    x=alt.X('Var1:O', title=None),
        #    y=alt.Y('Var2:O', title=None),
        #    color=alt.Color('Correlacao:Q', scale=alt.Scale(scheme='redblue'), legend=None),
        #    tooltip=['Var1', 'Var2', alt.Tooltip('Correlacao:Q', format=".2f")]
        #).properties(
        #    width=600,
        #    height=600,
        #    title="Mapa de Correla√ß√£o"
        #)

        # Adiciona os valores no centro dos quadrados
        #text = alt.Chart(corr).mark_text(size=10, color='black').encode(
        #    x='Var1:O',
        #    y='Var2:O',
        #    text=alt.Text('Correlacao:Q', format=".2f")
        #)

        #st.markdown("### üî• Mapa de Correla√ß√£o")
        #st.altair_chart(heatmap + text, use_container_width=False)
                
        

    st.markdown("### üìà Distribui√ß√£o de Vari√°veis")
    cols_to_plot = st.multiselect(
        "Selecione vari√°veis num√©ricas:",
        df.select_dtypes(include='number').columns.tolist(),
        default=["price", "sqft_living","bathrooms","waterfront","view","condition","grade"]
    )

    charts = []
    for col in cols_to_plot:
        base = alt.Chart(df).mark_bar(opacity=0.7).encode(
            alt.X(f"{col}:Q", bin=alt.Bin(maxbins=30), title=col),
            y='count()',
            tooltip=[col]
        ).properties(
            width=250,
            height=200,
            title=f"Distribui√ß√£o: {col}"
        )

        kde = alt.Chart(df).transform_density(
            col,
            as_=[col, 'density'],
        ).mark_line(color='red').encode(
            x=col,
            y='density:Q'
        )

        chart = base + kde  # sobrep√µe a densidade
        charts.append(chart)

    if charts:
        st.altair_chart(alt.hconcat(*charts), use_container_width=True)
    else:
        st.info("Selecione ao menos uma vari√°vel para visualizar.")
    
    
#
def q1_etapa2():
    st.markdown("---")
    st.subheader("üè† Q1 - 2 - Regressao lienar Modelo de Regress√£o Linear")
    st.info("Crie o modelo de regress√£o linear com m√©tricas de desempenho.")

    df = st.session_state.get("kc_df")
    if df is None:
        st.warning("‚ö†Ô∏è Os dados ainda n√£o foram carregados. Execute a Etapa 1 primeiro.")
        return

    df = df.drop(columns=["id", "date", "zipcode"], errors='ignore')
    df = df.dropna()

    cat_cols = ["waterfront", "view", "condition", "grade"]
    cols_possiveis = df.columns.tolist()
    if "price" in cols_possiveis:
        cols_possiveis.remove("price")

    # Fallback para vari√°veis padr√£o
    default_vars = ["sqft_living", "bathrooms"] + cat_cols
    default_vars = [v for v in default_vars if v in cols_possiveis]
    if not default_vars:
        default_vars = df.select_dtypes(include='number').columns.drop("price").tolist()[:2]

    st.markdown("### üéØ Sele√ß√£o de Vari√°veis Preditivas (Antes do One-Hot)")
    selected_features_raw = st.multiselect(
        "Selecione as vari√°veis para o modelo:",
        cols_possiveis,
        default=default_vars,
        key="seletor_variaveis_q1_etapa2"
    )

    # Separar vari√°veis num√©ricas e categ√≥ricas selecionadas
    selected_cat = [col for col in selected_features_raw if col in cat_cols]
    selected_num = [col for col in selected_features_raw if col not in cat_cols]

    if selected_features_raw:
        # Construir X com concatena√ß√£o segura
        frames = []
        if selected_num:
            frames.append(df[selected_num])
        if selected_cat:
            frames.append(pd.get_dummies(df[selected_cat], drop_first=True))

        if not frames:
            st.warning("‚ö†Ô∏è Nenhuma vari√°vel v√°lida foi selecionada.")
            return

        X = pd.concat(frames, axis=1)
        y = df["price"]

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        modelo = LinearRegression()
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)

        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test
        st.session_state["y_pred"] = y_pred

        st.markdown("### üìå Coeficientes do Modelo")
        coef_df = pd.DataFrame({"Vari√°vel": X.columns, "Coeficiente": modelo.coef_})
        st.dataframe(coef_df)

        st.markdown("### üìä M√©tricas de Avalia√ß√£o - Regressao Linear Classica")
        st.write(f"R¬≤: {r2_score(y_test, y_pred):.4f}")
        st.write(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
        st.write(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}")

def q1_etapa3():
    st.markdown("---")
    st.subheader("üè† Q1 - 3Ô∏è‚É£ Interpreta√ß√£o dos Resultados")
    if "X_test" in st.session_state and "y_test" in st.session_state and "y_pred" in st.session_state:
        X = st.session_state["X_test"]
        y = st.session_state["y_test"]
        y_pred = st.session_state["y_pred"]
        avaliar_pressupostos(X, y, y_pred)
    else:
        st.warning("‚ö†Ô∏è Execute a Etapa 2 para gerar o modelo antes de interpretar os resultados.")



def q1_etapa4():
    st.markdown("---")
    st.subheader("üè† Q1 - 4Ô∏è‚É£ Ajustes no Modelo")
    df = st.session_state.get("kc_df")
    if df is None:
        st.warning("‚ö†Ô∏è Os dados ainda n√£o foram carregados. Execute a Etapa 1 primeiro.")
        st.stop()

    # Preprocessamento
    df = df.drop(columns=["id", "date", "zipcode"], errors='ignore')
    df = df[df["price"] > 0].dropna()

    st.markdown("### üîß Aplicando Transforma√ß√£o Logar√≠tmica em 'price'")
    df["log_price"] = np.log(df["price"])

    # Define vari√°veis categ√≥ricas para poss√≠veis sele√ß√µes
    cat_cols = ["waterfront", "view", "condition", "grade"]
    df[cat_cols] = df[cat_cols].astype("category")

    # Cria lista de colunas poss√≠veis (incluindo categ√≥ricas)
    all_cols = df.select_dtypes(include=["number", "category"]).columns.tolist()
    all_cols.remove("price")
    if "log_price" in all_cols:
        all_cols.remove("log_price")

    # Sugerir vari√°veis padr√£o
    default_vars = ["sqft_living", "bathrooms"] + cat_cols
    default_vars = [v for v in default_vars if v in all_cols]

    selected_features_raw = st.multiselect(
        "Selecione vari√°veis preditoras (num√©ricas ou categ√≥ricas):",
        all_cols,
        default=default_vars,
        key="seletor_variaveis_q1_etapa4"
    )

    # Separa entre categ√≥ricas e num√©ricas
    selected_cat = [col for col in selected_features_raw if col in cat_cols]
    selected_num = [col for col in selected_features_raw if col not in cat_cols]

    if selected_features_raw:
        # Aplica one-hot apenas nas categ√≥ricas selecionadas
        X_parts = []
        if selected_num:
            X_parts.append(df[selected_num])
        if selected_cat:
            X_parts.append(pd.get_dummies(df[selected_cat], drop_first=True))

        if not X_parts:
            st.warning("‚ö†Ô∏è Nenhuma vari√°vel v√°lida foi selecionada.")
            return

        X = pd.concat(X_parts, axis=1)
        y = df["log_price"]

        # Divis√£o e modelo
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        modelo = LinearRegression()
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)

        # Coeficientes
        st.markdown("### üìå Coeficientes (log_price)")
        coef_df = pd.DataFrame({"Vari√°vel": X.columns, "Coeficiente": modelo.coef_})
        st.dataframe(coef_df)

        # M√©tricas
        st.markdown("### üìä M√©tricas de Avalia√ß√£o - Regress√£o Linear ap√≥s transforma√ß√£o Log")
        st.write(f"R¬≤: {r2_score(y_test, y_pred):.4f}")
        st.write(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
        st.write(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}")

        # Avalia√ß√£o de pressupostos
        avaliar_pressupostos(X_test, y_test, y_pred)

        # Lasso
        modelo_lasso = ajustar_modelo_lasso(X_train, y_train)
        y_pred_lasso = modelo_lasso.predict(X_test)

        st.markdown("### üìä M√©tricas de Avalia√ß√£o- Transforma√ß√£o Lasso")
        st.write(f"R¬≤: {r2_score(y_test, y_pred_lasso):.4f}")
        st.write(f"MAE: {mean_absolute_error(y_test, y_pred_lasso):.2f}")
        st.write(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lasso)):.2f}")

        avaliar_pressupostos(X_test, y_test, y_pred_lasso)


def q1_etapa5():
    st.subheader("üè† Q1 - 5Ô∏è‚É£ Tomada de Decis√£o")
    st.info("Descreva aplica√ß√µes pr√°ticas do modelo no contexto de neg√≥cio.")
    
    st.markdown("## üìå An√°lise da Quest√£o 1 ‚Äì Regress√£o Linear")

    st.markdown("""
    A an√°lise da Quest√£o 1 teve como objetivo prever os pre√ßos de im√≥veis na regi√£o de **King County** utilizando **Regress√£o Linear**.  
    A primeira etapa consistiu em uma **explora√ß√£o descritiva dos dados**, onde foram apresentadas estat√≠sticas como m√©dia, mediana e desvio padr√£o, al√©m de gr√°ficos de distribui√ß√£o e correla√ß√£o.  
    Essa an√°lise inicial ajudou a identificar vari√°veis mais relevantes para a modelagem, como `sqft_living`, `bathrooms` e `grade`.  
    Em seguida, foi constru√≠do um **modelo de regress√£o linear**, avaliado pelas m√©tricas:

    - **R¬≤**: `0.6084`
    - **MAE**: `R$ 155.744,00`
    - **RMSE**: `R$ 243.314,83`

    O desempenho inicial indicou uma **capacidade explicativa moderada**, mas com elevada variabilidade nos erros, sugerindo que o modelo cl√°ssico n√£o era suficientemente preciso.
    """)

    st.markdown("""
    Na etapa de interpreta√ß√£o, foram verificados os **pressupostos da regress√£o linear**, como:

    - Normalidade dos res√≠duos  
    - Homocedasticidade  
    - Aus√™ncia de multicolinearidade

    Todos os testes indicaram viola√ß√µes desses pressupostos.  
    Para tentar corrigir, foi aplicada a **transforma√ß√£o logar√≠tmica** na vari√°vel resposta `price`, resultando em um modelo com:

    - **R¬≤**: `0.6057`
    - **MAE**: `0.27`
    - **RMSE**: `0.34` (escala logar√≠tmica)

    Embora os res√≠duos t√™m se tornado mais sim√©tricos, os pressupostos **continuaram violados**.  
    Na sequ√™ncia, aplicou-se o modelo **Lasso com valida√ß√£o cruzada**, visando penalizar vari√°veis menos relevantes.  
    O desempenho do modelo Lasso foi:

    - **R¬≤**: `0.4882`
    - **MAE**: `0.31`
    - **RMSE**: `0.38`

    O Lasso teve desempenho inferior ao modelo log-transformado e **n√£o resolveu as viola√ß√µes estat√≠sticas**.
    """)

    st.markdown("""
    ### üíº Aplica√ß√£o no Neg√≥cio

    Mesmo com limita√ß√µes, os modelos desenvolvidos oferecem **insights √∫teis para neg√≥cios**.  
    Eles podem auxiliar:

    - Na **precifica√ß√£o inicial** de im√≥veis
    - Na **identifica√ß√£o de im√≥veis fora do padr√£o**
    - Na orienta√ß√£o de **investimentos em reformas**, destacando o impacto de vari√°veis como `grade` e `sqft_living`.

    Contudo, **devido √†s viola√ß√µes dos pressupostos**, recomenda-se o uso de **modelos n√£o lineares**, como:

    - √Årvores de Decis√£o  
    - Random Forest  
    - XGBoost

    Esses algoritmos lidam melhor com dados complexos e podem gerar **previs√µes mais confi√°veis e robustas** para o mercado imobili√°rio.
    """)

        

# =============================
# üîß Fun√ß√µes - Quest√£o 2
# =============================

def criar_coluna_arrival_date(df):
    """
    Adiciona uma coluna 'arrival_date' ao DataFrame com a data de chegada em formato datetime,
    convertendo o m√™s (por extenso) para n√∫mero.
    """
    # Dicion√°rio para convers√£o de nome do m√™s para n√∫mero
    meses = {
        'January': 1, 'February': 2, 'March': 3, 'April': 4,
        'May': 5, 'June': 6, 'July': 7, 'August': 8,
        'September': 9, 'October': 10, 'November': 11, 'December': 12
    }
    # Converter os nomes dos meses para n√∫mero
    df['arrival_month_num'] = df['arrival_date_month'].map(meses)
    
    # Criar a coluna de data de chegada
    df['arrival_date'] = pd.to_datetime(
        df['arrival_date_year'].astype(str) + '-' +
        df['arrival_month_num'].astype(str).str.zfill(2) + '-' +
        df['arrival_date_day_of_month'].astype(str).str.zfill(2)
    )
    
    #st.write(df["arrival_date"])
    
     # Cria coluna booking_date (data da reserva)
    df['booking_date'] = df['arrival_date'] - pd.to_timedelta(df['lead_time'], unit='D')
    
     #excluir arrival_date_year, arrival_date_month, arrival_date_week_number, arrival_date_day_of_month
    #variaves foram substitu√≠das por arrival_date

    df = df.drop(columns=["arrival_date_year", "arrival_date_month", "arrival_date_week_number", "arrival_date_day_of_month"], errors='ignore')

    return df

def pre_processamento(df):
    """
    Realiza pr√©-processamento b√°sico dos dados
    """
    # Remove duplicatas
    df = df.drop_duplicates()
    df = criar_coluna_arrival_date(df)
    df.drop(columns=['arrival_month_num'], inplace=True)
    
    return df



def q2_etapa1():
    st.subheader("üè® Q2 - a) An√°lise Descritiva dos Dados")
    st.info("Realize uma an√°lise descritiva da base de dados.")
    uploaded_file = 'src/hotel_bookings.csv'
    # Carregar os dados

    df2 = carregar_dados(uploaded_file)
    st.session_state["hb_df"] = df2
    st.success("‚úÖ Arquivo carregado com sucesso!")
    st.markdown("### üîç Preview dos Dados")
    st.dataframe(df2.head())
    
    
    # descrever cada coluna
    st.markdown("### üìò Dicion√°rio de Vari√°veis")
   # for col in df2.columns:
    #       st.markdown(f"**{col}**: {df2[col].dtype}")
    # fazer a tradu√ß√£o de cada coluna do df2


    # Definindo os dados da tabela
    dados = {
        "Vari√°vel": [
            "hotel", "is_canceled", "lead_time", "arrival_date_year", "arrival_date_month",
            "arrival_date_week_number", "arrival_date_day_of_month", "stays_in_weekend_nights",
            "stays_in_week_nights", "adults", "children", "babies", "meal", "country",
            "market_segment", "distribution_channel", "is_repeated_guest", "previous_cancellations",
            "previous_bookings_not_canceled", "reserved_room_type", "assigned_room_type",
            "booking_changes", "deposit_type", "agent", "company", "days_in_waiting_list",
            "customer_type", "adr", "required_car_parking_spaces", "total_of_special_requests",
            "reservation_status", "reservation_status_date", "arrival_date", "booking_date"
        ],
        "Tipo": [
            "Categ√≥rica", "Bin√°ria", "Num√©rica", "Num√©rica (inteira)", "Categ√≥rica",
            "Num√©rica (inteira)", "Num√©rica (inteira)", "Num√©rica (inteira)", "Num√©rica (inteira)",
            "Num√©rica (inteira)", "Num√©rica (inteira)", "Num√©rica (inteira)", "Categ√≥rica",
            "Categ√≥rica", "Categ√≥rica", "Categ√≥rica", "Bin√°ria", "Num√©rica (inteira)",
            "Num√©rica (inteira)", "Categ√≥rica", "Categ√≥rica", "Num√©rica (inteira)", "Categ√≥rica",
            "Categ√≥rica", "Categ√≥rica", "Num√©rica (inteira)", "Categ√≥rica", "Num√©rica (float)",
            "Num√©rica (inteira)", "Num√©rica (inteira)", "Categ√≥rica", "Data","Data","Data"
        ],
        "Descri√ß√£o": [
            "Tipo de hotel (ex: Resort, City)",
            "Cancelamento da reserva (1 = sim, 0 = n√£o)",
            "Tempo de anteced√™ncia da reserva (dias)",
            "Ano de chegada",
            "M√™s de chegada",
            "N√∫mero da semana de chegada (1 a 52/53)",
            "Dia do m√™s de chegada",
            "Noites de fim de semana na reserva",
            "Noites de semana na reserva",
            "N√∫mero de adultos",
            "N√∫mero de crian√ßas",
            "N√∫mero de beb√™s",
            "Tipo de refei√ß√£o inclu√≠da",
            "Pa√≠s de origem do h√≥spede",
            "Segmento de mercado",
            "Canal de distribui√ß√£o",
            "H√≥spede recorrente (1 = sim, 0 = n√£o)",
            "N√∫mero de cancelamentos anteriores",
            "Reservas anteriores n√£o canceladas",
            "Tipo de quarto reservado",
            "Tipo de quarto atribu√≠do",
            "Altera√ß√µes realizadas na reserva",
            "Tipo de dep√≥sito",
            "Agente de reservas",
            "Empresa associada √† reserva",
            "Dias na lista de espera",
            "Tipo de cliente",
            "Di√°ria m√©dia (Average Daily Rate)",
            "Espa√ßos de estacionamento necess√°rios",
            "Total de pedidos especiais",
            "Status final da reserva (Check-Out, Canceled, No-Show)",
            "Data do status final da reserva",
            "Data chegada",
            "Data da reserva"
        ]
    }

    # Criando o DataFrame
    df_variaveis = pd.DataFrame(dados)

    # Exibindo no Streamlit
    st.write("### Dicion√°rio de Vari√°veis do Dataset Hotel Booking Demand")
    st.dataframe(df_variaveis, use_container_width=True)

    # pre processamento
    df2 = pre_processamento(df2)
    st.session_state["hb_df"] = df2
    st.success("‚úÖ Pr√©-processamento conclu√≠do - Excluindo duplicadas se houver")
    #st.markdown("### üîç Preview dos Dados apos Inclusao da coluna data arrival_date e exclusao das colunas de data")
    #st.dataframe(df2.head())
    
    st.markdown("### üìä Estat√≠sticas Descritivas")
    #st.dataframe(df2.describe())
    st.markdown("### üßÆ Mediana das Vari√°veis Num√©ricas")
    st.dataframe(df2.select_dtypes(include='number').median())
    
    # graficos de distribui√ß√£o
    cols_numericas = [
        'lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children',
        'babies', 'previous_cancellations', 'previous_bookings_not_canceled',
        'booking_changes', 'days_in_waiting_list', 'adr',
        'required_car_parking_spaces', 'total_of_special_requests'
    ]
   
    st.markdown("### üìä Histogramas das Vari√°veis Num√©ricas por Cancelamento")

    charts = []
    for col in cols_numericas:
        chart = alt.Chart(df2).mark_bar(opacity=0.7).encode(
            x=alt.X(f'{col}:Q', bin=alt.Bin(maxbins=30), title=col),
            y=alt.Y('count()', title='Frequ√™ncia'),
            color=alt.Color('is_canceled:N', title='Cancelamento')
        ).properties(
            title=f'{col} - Distribui√ß√£o por Cancelamento',
            width=300,
            height=250
        )
        charts.append(chart)

    # Exibir os gr√°ficos em 3 colunas
    num_cols = 3
    rows = [charts[i:i+num_cols] for i in range(0, len(charts), num_cols)]

    for row in rows:
        cols = st.columns(num_cols)
        for col_chart, col_container in zip(row, cols):
            with col_container:
                st.altair_chart(col_chart, use_container_width=True)


    

def q2_etapa2():
    
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.linear_model import LogisticRegression
       # graficar a distribui√ß√£o da vari√°vel dependente
    import plotly.express as px
    # importar pandas como pd
    import pandas as pd
    import streamlit as st
    import altair as alt
    
    
    st.subheader("üè® Q2 - b) Modelo de Regress√£o Log√≠stica")
    st.info("Construa o modelo de regress√£o log√≠stica e avalie seu desempenho.")

    df2 = st.session_state.get("hb_df")
    if df2 is None:
        st.warning("‚ö†Ô∏è Os dados ainda n√£o foram carregados. Execute a Etapa 1 primeiro.")
        return
    
    y = df2['is_canceled']
    X = df2.drop(columns='is_canceled')

    
        # Separe as features do tipo categ√≥rica e num√©rica
    cols_numericas = [
        'lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children',
        'babies', 'previous_cancellations', 'previous_bookings_not_canceled',
        'booking_changes', 'days_in_waiting_list', 'adr',
        'required_car_parking_spaces', 'total_of_special_requests'
    ]

    cols_categoricas = [
        'hotel', 'meal', 
        #'country',
        'market_segment', 'distribution_channel',
        'is_repeated_guest', 
        #'reserved_room_type', 'assigned_room_type',
        'deposit_type', 
        #'agent',
       # 'company', 
        'customer_type'
    ]
    

    # 1. Balanceamento das classes
    st.markdown("**Distribui√ß√£o da vari√°vel dependente (is_canceled):**")
    st.dataframe(y.value_counts(normalize=True).rename("Propor√ß√£o").to_frame())

    fig = px.pie(y.value_counts(normalize=True).rename("Propor√ß√£o").to_frame(), 
                 values='Propor√ß√£o', 
                 names=y.value_counts().index, 
                 title="Distribui√ß√£o de Cancelamentos (is_canceled)",
                 color_discrete_sequence=px.colors.qualitative.Set2)    
    st.plotly_chart(fig, use_container_width=True)
    

   
   # se distribui√ß√£o for desbalanceada, aplicar oversampling ou undersampling
    from imblearn.over_sampling import RandomOverSampler
    from imblearn.under_sampling import RandomUnderSampler
    from imblearn.pipeline import Pipeline as ImbPipeline
    from collections import Counter
    # Verificar o balanceamento das classes
    
   
    counter = Counter(y)
    #st.write(f"Classes antes do balanceamento: {counter}")
    # Se a distribui√ß√£o for desbalanceada, aplicar oversampling ou undersampling

    if counter[0] < counter[1]:
        st.warning("‚ö†Ô∏è Distribui√ß√£o desbalanceada. Aplicando oversampling para balancear as classes.")
        
        
        # Aplicar oversampling
        oversample = RandomOverSampler(sampling_strategy='minority', random_state=42)
        X_resampled, y_resampled = oversample.fit_resample(df2[cols_numericas + cols_categoricas], y)
        st.write(f"Classes ap√≥s oversampling: {Counter(y_resampled)}")
    elif counter[0] > counter[1]:
        st.warning("‚ö†Ô∏è Distribui√ß√£o desbalanceada. Aplicando undersampling para balancear as classes.")
        # Aplicar undersampling
        undersample = RandomUnderSampler(sampling_strategy='majority', random_state=42)
        X_resampled, y_resampled = undersample.fit_resample(df2[cols_numericas + cols_categoricas], y)
       # st.write(f"Classes ap√≥s undersampling: {Counter(y_resampled)}")
       
            # 3. Verifica√ß√£o de valores ausentes
        # 3. Verifica√ß√£o de valores ausentes no dataset balanceado
        st.markdown("**Valores ausentes nas colunas do dataset balanceado:**")
        missing_values = X.isnull().sum()
        missing_values = missing_values[missing_values > 0].sort_values(ascending=False)
        if missing_values.empty:
            st.success("‚úÖ N√£o h√° valores ausentes nas colunas do dataset balanceado.")
        else:
            st.dataframe(missing_values.rename("Valores Ausentes").to_frame())
            st.markdown("""
            Optou-se pela remo√ß√£o das vari√°veis `country`, `agent` e `company` do modelo devido √† alta propor√ß√£o 
            de valores ausentes e √† elevada cardinalidade dessas vari√°veis, que dificultariam o processamento e aumentariam 
            o risco de overfitting. Em contrapartida, a vari√°vel `hotel` foi mantida por sintetizar informa√ß√µes relevantes
            sobre o tipo de hospedagem e o perfil do h√≥spede, sendo capaz de capturar parte da variabilidade representada 
            pelas vari√°veis exclu√≠das. Dessa forma, o modelo permanece mais simples, robusto e eficiente, sem perda significativa de informa√ß√£o.
            """)

   
    else:
        st.success("‚úÖ Distribui√ß√£o balanceada. N√£o √© necess√°rio aplicar oversampling ou undersampling.")
        X_resampled = df2[cols_numericas + cols_categoricas]
        y_resampled = y
   
    
    # Exibir a distribui√ß√£o das classes ap√≥s o balanceamento
    st.markdown("**Distribui√ß√£o da vari√°vel dependente (is_canceled) ap√≥s balanceamento:**")
    st.dataframe(y_resampled.value_counts(normalize=True).rename("Propor√ß√£o").to_frame())
    # graficar a distribui√ß√£o da vari√°vel dependente ap√≥s balanceamento
    fig = px.pie(y_resampled.value_counts(normalize=True).rename("Propor√ß√£o").to_frame(),
                 values='Propor√ß√£o', 
                 names=y_resampled.value_counts().index, 
                 title="Distribui√ß√£o de Cancelamentos (is_canceled) ap√≥s Balanceamento",
                 color_discrete_sequence=px.colors.qualitative.Set2)
    st.plotly_chart(fig, use_container_width=True)

   # 2. Multicolinearidade (VIF) - Exemplo para as features num√©ricas
  # Imputa√ß√£o dos valores ausentes nas vari√°veis num√©ricas do dataset balanceado
    X_num_vif = pd.DataFrame(X_resampled[cols_numericas], columns=cols_numericas)
    X_num_vif = X_num_vif.fillna(X_num_vif.mean())

    # Calcular VIF
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    vif_data = pd.DataFrame()
    vif_data["Feature"] = X_num_vif.columns
    vif_data["VIF"] = [variance_inflation_factor(X_num_vif.values, i) for i in range(X_num_vif.shape[1])]
    st.markdown("**Fatores de Infla√ß√£o de Vari√¢ncia (VIF):**")
    st.dataframe(vif_data)

    # validar se o VIF √© maior 10
    vif_threshold = 10
    if any(vif_data["VIF"] > vif_threshold):
        st.warning(f"‚ö†Ô∏è Algumas vari√°veis t√™m VIF maior que {vif_threshold}. Considere remover ou combinar vari√°veis.")
    else:
        st.success(f"‚úÖ Todas as vari√°veis t√™m VIF abaixo de {vif_threshold}. N√£o h√° multicolinearidade significativa.")


    
  
 
 
    # verificar linearidade entre as vari√°veis num√©ricas
    num_vars = [
        'lead_time'
    ]

    st.markdown("### An√°lise de Linearidade com Boxplot das Vari√°veis Num√©ricas por Cancelamento")

    import altair as alt
    for col in num_vars:
        chart = alt.Chart(df2).mark_boxplot(extent='min-max').encode(
            x=alt.X('is_canceled:N', title='Cancelamento (0 = N√£o, 1 = Sim)'),
            y=alt.Y(f'{col}:Q', title=col),
            color=alt.Color('is_canceled:N', legend=None)
        ).properties(
            title=f'{col} vs Cancelamento',
            width=400,
            height=300
        )
        st.altair_chart(chart, use_container_width=True)
  
    st.markdown("""
    Boxplots foram utilizados para comparar a distribui√ß√£o das vari√°veis num√©ricas entre as classes da vari√°vel dependente 
    (`is_canceled`). Observou-se que algumas vari√°veis, como `lead_time`, apresentaram diferen√ßas nas medianas entre as classes,
    sugerindo rela√ß√£o monot√¥nica desej√°vel para a regress√£o log√≠stica. Para as demais vari√°veis num√©ricas, essa tend√™ncia n√£o foi
    t√£o evidente, indicando que a rela√ß√£o linear com o logit pode ser mais fraca ou inexistente nessas vari√°veis. Ainda assim, 
    todas as vari√°veis foram mantidas no modelo, reconhecendo que sua contribui√ß√£o, mesmo que n√£o estritamente linear, pode ser
    relevante para a previs√£o. Recomenda-se, em aplica√ß√µes futuras, avaliar transforma√ß√µes ou m√©todos mais flex√≠veis caso o ajuste 
    linear n√£o seja suficiente.
    """)
    st.success("‚úÖ Pressupostos iniciais validados com sucesso! (Linearidade, Multicolinearidade, Balanceamento) Pronto para treinar o modelo de Regress√£o Log√≠stica.")

    # Pr√©-processamento
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, cols_numericas),
            ('cat', categorical_transformer, cols_categoricas)
        ]
    )

    pipeline = Pipeline(steps=[
        ('prep', preprocessor),
        ('logreg', LogisticRegression(max_iter=1000))
    ])


    # Split
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

    # Treinamento
    #pipeline.fit(X_train, y_train)
    
    # Treinamento
    pipeline.fit(X_train, y_train)

    # Previs√µes
    y_pred = pipeline.predict(X_test)
    

    import numpy as np
    import pandas as pd

    # Obter nomes das features do pipeline para tabela de coeficientes
    feature_names = pipeline.named_steps['prep'].get_feature_names_out()
    coef = pipeline.named_steps['logreg'].coef_[0]
    odds = np.exp(coef)

    coef_table = pd.DataFrame({
        'Vari√°vel': feature_names,
        'Coeficiente': coef.round(3),
        'Odds Ratio': odds.round(3),
        'Interpreta√ß√£o': [
            "Aumenta chance de cancelamento" if c > 0 else "Reduz chance de cancelamento"
            for c in coef
        ]
    }).sort_values(by='Coeficiente', ascending=False)
        
    st.markdown("### üìä Coeficientes do Modelo de Regress√£o Log√≠stica")
    st.dataframe(coef_table) 
    # Salve o pipeline e dados de teste no session_state
    st.session_state["model"] = pipeline
   
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

    # Calcular m√©tricas
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    conf_mat = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    # Exibir resultados no Streamlit
    st.markdown(f"""
    **Acur√°cia:** {acc:.3f}  
    **Precis√£o:** {prec:.3f}  
    **Recall:** {rec:.3f}  
    **F1-score:** {f1:.3f}  
    """)

    st.markdown("**Matriz de Confus√£o:**")
    st.dataframe(conf_mat)

    st.markdown("**Relat√≥rio de Classifica√ß√£o:**")
    st.text(report)
    
    
    # Tabela de m√©tricas
    metricas = pd.DataFrame({
        "M√©trica": ["Acur√°cia", "Precis√£o", "Recall", "F1-score"],
        "Valor": [0.721, 0.708, 0.754, 0.730],
        "Interpreta√ß√£o": [
            "O modelo acertou 72,1% das previs√µes totais (canceladas e n√£o canceladas).",
            "Das reservas que o modelo previu como canceladas, 70,8% realmente foram.",
            "O modelo identificou corretamente 75,4% das reservas que foram canceladas.",
            "M√©dia harm√¥nica entre precis√£o e recall, indicando bom equil√≠brio."
        ]
    })
  
    st.markdown("Explica√ß√£o")
    st.dataframe(metricas)

     
     
def q2_etapa3():
        st.markdown("---")
        st.subheader("üè® Q2 - c) An√°lise das Features")
        st.info("Analise a import√¢ncia das vari√°veis no modelo de regress√£o log√≠stica.")

        df2 = st.session_state.get("hb_df")
        if df2 is None:
            st.warning("‚ö†Ô∏è Os dados ainda n√£o foram carregados. Execute a Etapa 1 primeiro.")
            return
        
        
        if "model" not in st.session_state:
            st.warning("‚ö†Ô∏è Execute a Etapa 2 para treinar o modelo antes de analisar as features.")
            return

        model = st.session_state["model"]
        #X_test = st.session_state["X_test"]

        feature_names = model.named_steps['prep'].get_feature_names_out()
        coef = model.named_steps['logreg'].coef_[0]

        print(len(feature_names), len(coef))  # Ambos devem ter o mesmo tamanho

        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': coef
        }).sort_values(by='Importance', ascending=False)

        st.markdown("### üìä Import√¢ncia das Vari√°veis")
        st.dataframe(feature_importance)

        # Gr√°fico de barras
        fig = px.bar(feature_importance, x='Feature', y='Importance', title='Import√¢ncia das Vari√°veis')
        st.plotly_chart(fig, use_container_width=True)

        st.subheader("An√°lise Final das Principais Vari√°veis")

        st.markdown("""
        **Cinco vari√°veis que mais aumentam a chance de cancelamento:**
        1. **lead_time:** Reservas feitas com muita anteced√™ncia t√™m maior risco de cancelamento.
        2. **previous_cancellations:** H√≥spedes com hist√≥rico pr√©vio de cancelamentos tendem a cancelar novamente.
        3. **market_segment_Undefined:** Reservas de segmento indefinido apresentam mais risco de cancelamento.
        4. **customer_type_Transient:** H√≥spedes transit√≥rios s√£o mais propensos ao cancelamento.
        5. **market_segment_Complementary:** Reservas complementares (gratuitas ou promocionais) t√™m mais chance de serem canceladas.

        **Cinco vari√°veis que mais reduzem a chance de cancelamento:**
        1. **required_car_parking_spaces:** Necessidade de vaga de estacionamento est√° associada √† menor chance de cancelamento.
        2. **total_of_special_requests:** Mais pedidos especiais significam menor risco de cancelamento.
        3. **deposit_type_Non Refund:** Dep√≥sitos n√£o reembols√°veis praticamente impedem cancelamentos.
        4. **customer_type_Group:** H√≥spedes em grupo tendem a cancelar menos.
        5. **(Outra vari√°vel relevante, como booking_changes):** Mudan√ßas na reserva podem indicar maior comprometimento e, portanto, menor risco de cancelamento.

        Essas vari√°veis ajudam a identificar perfis de reservas e h√≥spedes mais propensos ao cancelamento, permitindo a√ß√µes preventivas por parte do hotel.
        """)

        
        
def q2_etapa4():
    st.markdown("---")
    st.subheader("üè® Q2 - d) Justificativa do M√©todo")
    st.info("Discuta a escolha do modelo de regress√£o log√≠stica.")

    df2 = st.session_state.get("hb_df")
    if df2 is None:
        st.warning("‚ö†Ô∏è Os dados ainda n√£o foram carregados. Execute a Etapa 1 primeiro.")
        return

    if "model" not in st.session_state:
        st.warning("‚ö†Ô∏è Execute a Etapa 2 para treinar o modelo antes de justificar o m√©todo.")
        return

    model = st.session_state["model"]
 

    # Justificativa do m√©todo
    st.markdown("""
    A regress√£o log√≠stica foi escolhida por ser o m√©todo mais adequado para problemas de classifica√ß√£o bin√°ria, como √© o caso da previs√£o de cancelamento de reservas, cuja vari√°vel alvo assume apenas dois valores: cancelado (1) ou n√£o cancelado (0).

    Diferentemente da regress√£o linear, que prev√™ valores cont√≠nuos e pode gerar resultados fora do intervalo [0, 1], a regress√£o log√≠stica modela diretamente a probabilidade de ocorr√™ncia de um evento. Seu resultado est√° sempre restrito ao intervalo de 0 a 1, permitindo interpretar a sa√≠da do modelo como a probabilidade de cancelamento de cada reserva.

    Al√©m disso, a regress√£o log√≠stica lida melhor com a natureza categ√≥rica da vari√°vel resposta e permite calcular m√©tricas de avalia√ß√£o apropriadas, como acur√°cia, precis√£o, recall e F1-score, que s√£o fundamentais para problemas de classifica√ß√£o. Portanto, a regress√£o log√≠stica oferece maior robustez, interpretabilidade e adequa√ß√£o estat√≠stica para o contexto deste estudo, sendo prefer√≠vel √† regress√£o linear.
    """)



# =============================
# üîß Fun√ß√µes - Quest√£o 3
# =============================
def q3_etapa1():
    st.subheader("üåç Q3 - a) An√°lise Descritiva")
    st.info("Explore dados por pa√≠s, quantidade e pre√ßo.")
        
        # Carregar a planilha (ou use df se j√° estiver carregado)
    @st.cache_data
    def carregar_dados():
        return pd.read_csv("src/planilha_combinada.csv")

    df = carregar_dados()

    # Total de linhas
    total_linhas = len(df)

    # Calcular valores ausentes
    valores_ausentes = df.isnull().sum()
    percentual_ausentes = (valores_ausentes / total_linhas) * 100

    # Juntar em um √∫nico DataFrame para exibi√ß√£o
    tabela_ausentes = pd.DataFrame({
        'Valores Ausentes': valores_ausentes,
        'Percentual (%)': percentual_ausentes.round(2)
    })

    # Filtrar apenas colunas com pelo menos 1 valor ausente
    tabela_ausentes = tabela_ausentes[tabela_ausentes['Valores Ausentes'] > 0]

    # Exibir
    print("üìâ Valores Ausentes por Coluna:")
    print(tabela_ausentes.sort_values(by="Percentual (%)", ascending=False))
    
    # mostrar valores ausentes no streamlit
    st.markdown("### üìâ Valores Ausentes por Coluna")
    st.dataframe(tabela_ausentes.sort_values(by="Percentual (%)", ascending=False))
    
    
    # Exibir o DataFrame original
    st.markdown("### üìä Preview dos Dados")
    st.dataframe(df)
    # Exibir estat√≠sticas descritivas
    st.markdown("### üìà Estat√≠sticas Descritivas")
    st.dataframe(df.describe())
    
    
    # Amostragem de 100 mil registros para acelerar a visualiza√ß√£o
    df_amostra = df.sample(n=100_000, random_state=42)

    vendas_pais = df_amostra.groupby("Country")["Price"].sum().reset_index()
    vendas_pais = vendas_pais.sort_values(by="Price", ascending=False)

    st.markdown("### üìä Distribui√ß√£o de Vendas por Pa√≠s (com amostragem)")
    st.dataframe(vendas_pais)
    
    #graficar a distribui√ß√£o de vendas por pa√≠s
    import plotly.express as px
    fig = px.bar(vendas_pais, x="Country", y="Price", title="Distribui√ß√£o de Vendas por Pa√≠s (Amostragem)",
                 color="Price", color_continuous_scale=px.colors.sequential.Plasma)
    
    # Exibir a distribui√ß√£o de vendas por pa√≠s
    st.plotly_chart(fig)

    st.markdown("### üìä An√°lise de Quantidade e Pre√ßo por Pa√≠s")  
    # Agrupar por pa√≠s e calcular a soma de quantidade e pre√ßo
    vendas_pais_quantidade = df_amostra.groupby("Country")["Quantity"].sum().reset_index()
    vendas_pais_preco = df_amostra.groupby("Country")["Price"].sum().reset_index()
    vendas_pais_quantidade = vendas_pais_quantidade.sort_values(by="Quantity", ascending=False)
    vendas_pais_preco = vendas_pais_preco.sort_values(by="Price", ascending=False)
    st.dataframe(vendas_pais_quantidade)
    st.dataframe(vendas_pais_preco)
    # Gr√°fico de barras da quantidade de vendas por pa√≠s
    fig_quantidade = px.bar(vendas_pais_quantidade, x="Country", y="Quantity", title="Quantidade de Vendas por Pa√≠s (Amostragem)",
                            color="Quantity", color_continuous_scale=px.colors.sequential.Viridis)

    st.plotly_chart(fig_quantidade)
    
    
    # stockcod por pa√≠s
    vendas_pais_stockcode = df.groupby("Country")["StockCode"].nunique().reset_index()
    vendas_pais_stockcode = vendas_pais_stockcode.sort_values(by="StockCode", ascending=False)
    st.markdown("### üìä Quantidade de Produtos Vendidos por Pa√≠s")
    st.dataframe(vendas_pais_stockcode)
    # Exibir a quantidade de vendas por pa√≠s
   # st.markdown("### üìä Quantidade de Vendas por Pa√≠s")
   # st.dataframe(df.groupby("Country")["Quantity"].sum().reset_index())
    
    # Gr√°fico de barras da quantidade de vendas por pa√≠s
    #fig = px.bar(df, x="Country", y="Quantity", title="Quantidade de Vendas por Pa√≠s",
    #             color="Quantity", color_continuous_scale=px.colors.sequential.Viridis)
    #st.plotly_chart(fig)
    
    # medias de quantidade de produtos vendidos por pa√≠s
    #st.markdown("### üìä M√©dia de Quantidade Vendida por Pa√≠s")
    #st.dataframe(df.groupby("Country")["Quantity"].mean().reset_index())
    # Gr√°fico de barras da m√©dia de quantidade vendida por pa√≠s
    #fig = px.bar(df, x="Country", y="Quantity", title="M√©dia de Quantidade Vendida por Pa√≠s",
    #             color="Quantity", color_continuous_scale=px.colors.sequential.Cividis)
    #st.plotly_chart(fig)
    

    # Exibir a m√©dia de pre√ßo por pa√≠s
    #st.markdown("### üìä M√©dia de Pre√ßo por Pa√≠s")
    #st.dataframe(df.groupby("Country")["Price"].mean().reset_index())
    # Gr√°fico de barras da m√©dia de pre√ßo por pa√≠s
    #fig = px.bar(df, x="Country", y="Price", title="M√©dia de Pre√ßo por Pa√≠s",
    #             color="Price", color_continuous_scale=px.colors.sequential.Inferno)
    #st.plotly_chart(fig)
    


    # Exibir a quantidade de vendas por categoria
    #st.markdown("### üìä Quantidade de Vendas por Categoria")
    #st.dataframe(df.groupby("Category")["Quantity"].sum().reset_index())
    # Gr√°fico de barras da quantidade de vendas por categoria
    #fig = px.bar(df, x="Category", y="Quantity", title="Quantidade de Vendas por Categoria",
    #             color="Quantity", color_continuous_scale=px.colors.sequential.Viridis)
    #st.plotly_chart(fig)


def q3_etapa2():
    st.subheader("üåç Q3 - b) ANOVA entre Pa√≠ses")
    st.info("Apresente F, p-valor e interprete o teste.")

def q3_etapa3():
    st.subheader("üåç Q3 - c) Ajustes no Modelo")
    st.info("Verifique normalidade, homocedasticidade etc.")

def q3_etapa4():
    st.subheader("üåç Q3 - d) Interpreta√ß√£o e Decis√£o")
    st.info("Decis√µes com base nas diferen√ßas de m√©dias.")

# =============================
# üîß Fun√ß√µes - Quest√£o 4
# =============================
def q4_etapa1():
    st.subheader("üõí Q4 - a) Discuss√£o do Problema")
    st.info("Import√¢ncia de prever reclama√ß√µes no varejo.")

def q4_etapa2():
    st.subheader("üõí Q4 - b) An√°lise Descritiva")
    st.info("Examine vari√°veis ligadas √† vari√°vel 'Complain'.")

def q4_etapa3():
    st.subheader("üõí Q4 - c) Sele√ß√£o de Modelos")
    st.info("Compare Logistic, √Årvores, Random Forest, XGBoost.")

def q4_etapa4():
    st.subheader("üõí Q4 - d) SHAP e Explicabilidade")
    st.info("Use SHAP para entender a influ√™ncia das vari√°veis.")

def q4_etapa5():
    st.subheader("üõí Q4 - e) K-Means / DBSCAN")
    st.info("Clusteriza√ß√£o e detec√ß√£o de outliers por perfil.")

def q4_etapa6():
    st.subheader("üõí Q4 - f) Decis√£o Estrat√©gica")
    st.info("Sugira melhorias com base nos insights obtidos.")

# =============================
# üîß Fun√ß√µes - Quest√£o 5
# =============================
def q5_etapa1():
    st.subheader("üìå Q5 - Em breve")
    st.info("Espa√ßo reservado para uma nova quest√£o.")


# =============================
# ‚ñ∂Ô∏è APP Streamlit
# =============================
st.set_page_config(page_title="üìä Prova Final - An√°lise Estat√≠stica", layout="wide")
st.title("üìö Prova Final - An√°lise Estat√≠stica de Dados e Informa√ß√µes")
st.markdown("üë©‚Äçüéì Desenvolvido por: [Seu Nome] &nbsp;&nbsp;&nbsp;&nbsp;üìÖ Julho 2025")

# MENU LATERAL
with st.sidebar:
    st.title("üß≠ Menu da Prova")
    mostrar_todas = st.checkbox("‚úÖ Mostrar todas as quest√µes", value=False)

    # Quest√£o 1
    with st.expander(" Quest√£o 1 - Regress√£o Linear (Im√≥veis)", expanded=mostrar_todas):
        show_q1_e1 = mostrar_todas or st.checkbox("1Ô∏è An√°lise Descritiva", key="q1e1")
        show_q1_e2 = mostrar_todas or st.checkbox("2Ô∏è Modelo de Regress√£o Linear", key="q1e2")
        show_q1_e3 = mostrar_todas or st.checkbox("3Ô∏è Interpreta√ß√£o dos Resultados", key="q1e3")
        show_q1_e4 = mostrar_todas or st.checkbox("4Ô∏è Ajustes no Modelo", key="q1e4")
        show_q1_e5 = mostrar_todas or st.checkbox("5Ô∏è Tomada de Decis√£o", key="q1e5")

    # Quest√£o 2
    with st.expander("üè® Quest√£o 2 - Regress√£o Log√≠stica (Reservas)", expanded=mostrar_todas):
        show_q2_e1 = mostrar_todas or st.checkbox("a) An√°lise Descritiva", key="q2e1")
        show_q2_e2 = mostrar_todas or st.checkbox("b) Modelo de Regress√£o Log√≠stica", key="q2e2")
        show_q2_e3 = mostrar_todas or st.checkbox("c) An√°lise das Features", key="q2e3")
        show_q2_e4 = mostrar_todas or st.checkbox("d) Justificativa do M√©todo", key="q2e4")

    # Quest√£o 3
    with st.expander("üåç Quest√£o 3 - ANOVA (Vendas por Pa√≠s)", expanded=mostrar_todas):
        show_q3_e1 = mostrar_todas or st.checkbox("a) An√°lise Descritiva", key="q3e1")
        show_q3_e2 = mostrar_todas or st.checkbox("b) ANOVA entre Pa√≠ses", key="q3e2")
        show_q3_e3 = mostrar_todas or st.checkbox("c) Ajustes no Modelo", key="q3e3")
        show_q3_e4 = mostrar_todas or st.checkbox("d) Interpreta√ß√£o e Decis√£o", key="q3e4")

    # Quest√£o 4
    with st.expander("üõí Quest√£o 4 - Reclama√ß√µes de Clientes", expanded=mostrar_todas):
        show_q4_e1 = mostrar_todas or st.checkbox("a) Discuss√£o do Problema", key="q4e1")
        show_q4_e2 = mostrar_todas or st.checkbox("b) An√°lise Descritiva", key="q4e2")
        show_q4_e3 = mostrar_todas or st.checkbox("c) Sele√ß√£o de Modelos", key="q4e3")
        show_q4_e4 = mostrar_todas or st.checkbox("d) SHAP e Explicabilidade", key="q4e4")
        show_q4_e5 = mostrar_todas or st.checkbox("e) K-Means / DBSCAN", key="q4e5")
        show_q4_e6 = mostrar_todas or st.checkbox("f) Decis√£o Estrat√©gica", key="q4e6")

    # Quest√£o 5
    with st.expander("üìå Quest√£o 5 - [Reservado]", expanded=mostrar_todas):
        show_q5_e1 = mostrar_todas or st.checkbox("‚û°Ô∏è Em breve", key="q5e1")


# CHAMADAS DAS FUN√á√ïES DE CADA ITEM
if show_q1_e1: q1_etapa1()
if show_q1_e2: q1_etapa2()
if show_q1_e3: q1_etapa3()
if show_q1_e4: q1_etapa4()
if show_q1_e5: q1_etapa5()

if show_q2_e1: q2_etapa1()
if show_q2_e2: q2_etapa2()
if show_q2_e3: q2_etapa3()
if show_q2_e4: q2_etapa4()

if show_q3_e1: q3_etapa1()
if show_q3_e2: q3_etapa2()
if show_q3_e3: q3_etapa3()
if show_q3_e4: q3_etapa4()

if show_q4_e1: q4_etapa1()
if show_q4_e2: q4_etapa2()
if show_q4_e3: q4_etapa3()
if show_q4_e4: q4_etapa4()
if show_q4_e5: q4_etapa5()
if show_q4_e6: q4_etapa6()

if show_q5_e1: q5_etapa1()

# Rodap√©
st.markdown("---")
st.markdown("üßÆ **Prova Final - Ci√™ncia de Dados Aplicada**  \nüë©‚Äçüè´ Professor(a): [Nome do Professor]  \nüìä Universidade XYZ - 2025")

